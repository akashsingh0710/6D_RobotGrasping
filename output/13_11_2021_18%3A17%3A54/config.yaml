!!python/object/new:easydict.EasyDict
dictitems:
  DATA_ROOT_DIR: data/scenes
  EPOCHS: 200
  EXPERIMENT_OBJ_INDEX_DIR: experiments/object_index
  IMG_SIZE: &id011
  - 112
  - 112
  LOG: true
  MODEL_SPEC_DIR: experiments/model_spec
  OBJECT_DATA_DIR: data/objects
  OFFLINE_BATCH_SIZE: 100
  OFFLINE_RL_MEMORY_SIZE: 100000
  ONPOLICY_MEMORY_SIZE: -1
  OUTPUT_DIR: output
  OUTPUT_MISC_DIR: output_misc
  RL_DATA_ROOT_DIR: data/scenes
  RL_IMG_SIZE: &id012
  - 112
  - 112
  RL_MAX_STEP: 20
  RL_MEMORY_SIZE: 100000
  RL_MODEL_SPEC: experiments/model_spec/rl_pointnet_model_spec.yaml
  RL_SAVE_DATA_NAME: data_50k.npz
  RL_SAVE_DATA_ROOT_DIR: data/offline_data
  RL_TEST_SCENE: data/gaddpg_scenes
  RL_TRAIN: &id013 !!python/object/new:easydict.EasyDict
    dictitems:
      DAGGER_MAX_STEP: 18
      DAGGER_MIN_STEP: 5
      DAGGER_RATIO: 0.5
      DART_MAX_STEP: 13
      DART_MIN_STEP: 5
      DART_RATIO: 0.5
      ENV_FAR: 0.5
      ENV_NEAR: 0.2
      ENV_RESET_TRIALS: 7
      EXPERT_INIT_MAX_STEP: 15
      EXPERT_INIT_MIN_STEP: 0
      RL: false
      SAVE_EPISODE_INTERVAL: 50
      accumulate_points: true
      action_noise: 0.01
      batch_size: 256
      bc_reward_flag: false
      buffer_full_size: -1
      buffer_start_idx: 0
      change_dynamics: false
      channel_num: 5
      clip_grad: 0.5
      concat_option: point_wise
      critic_aux: true
      critic_extra_latent: -1
      critic_goal: false
      dagger: false
      dart: true
      ddpg_coefficients: &id001
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 0.2
      domain_randomization: false
      env_name: PandaYCBEnv
      env_num_objs: 1
      expert_initial_state: true
      explore_cap: 0.5
      explore_ratio: 0.1
      explore_ratio_list: &id002
      - 0.1
      - 0.2
      - 0.3
      - 0.5
      - 0.6
      - 0.7
      - 0.8
      feature_input_dim: 512
      fill_data_step: 10
      fix_timestep_test: true
      gamma: 0.95
      goal_reward_flag: false
      head_lr: 0.0003
      hidden_size: 256
      index_file: experiments/object_index/extra_shape.json
      index_split: train
      init_distance_high: 0.45
      init_distance_low: 0.15
      load_buffer: false
      load_obj_num: 40
      load_scene_joint: false
      load_test_scene_new: false
      log: true
      lr: 0.0003
      lr_gamma: 0.5
      max_epoch: 150000
      max_num_pts: 20000
      mix_milestones: &id003
      - 4000
      - 8000
      - 20000
      - 40000
      - 60000
      - 80000
      - 100000
      - 140000
      - 180000
      mix_policy_ratio_list: &id004
      - 0.1
      - 0.2
      mix_value_ratio_list: &id005
      - 1.0
      new_scene: true
      noise_ratio_list: &id006
      - 3.0
      - 2.5
      - 2.0
      - 1.5
      - 1
      - 0.5
      noise_type: uniform
      num_remotes: 8
      off_policy: true
      online_buffer_ratio: 0.0
      onpolicy: false
      overwrite_feat_milestone: &id007 []
      policy_aux: true
      policy_extra_latent: -1
      policy_goal: false
      policy_milestones: &id008
      - 20000
      - 40000
      - 60000
      - 80000
      policy_update_gap: 2
      pt_accumulate_ratio: 0.95
      refill_buffer: true
      reinit_factor: 3
      reinit_lr: 0.0001
      reinit_optim: false
      sa_channel_concat: true
      save_epoch: &id009
      - 5000
      - 20000
      - 40000
      - 80000
      - 140000
      - 180000
      - 200000
      self_supervision: false
      shared_feature: false
      shared_objects_across_worker: false
      target_update_interval: 3000
      tau: 0.0001
      train_feature: true
      train_goal_feature: false
      train_value_feature: true
      uniform_num_pts: 1024
      updates_per_step: 4
      use_action_limit: true
      use_expert_plan: false
      use_image: false
      use_point_state: true
      use_time: true
      value_lr: 0.0003
      value_lr_gamma: 0.5
      value_milestones: &id010
      - 20000
      - 40000
      - 60000
      - 80000
      value_model: false
      visdom: true
    state:
      DAGGER_MAX_STEP: 18
      DAGGER_MIN_STEP: 5
      DAGGER_RATIO: 0.5
      DART_MAX_STEP: 13
      DART_MIN_STEP: 5
      DART_RATIO: 0.5
      ENV_FAR: 0.5
      ENV_NEAR: 0.2
      ENV_RESET_TRIALS: 7
      EXPERT_INIT_MAX_STEP: 15
      EXPERT_INIT_MIN_STEP: 0
      RL: false
      SAVE_EPISODE_INTERVAL: 50
      accumulate_points: true
      action_noise: 0.01
      batch_size: 256
      bc_reward_flag: false
      buffer_full_size: -1
      buffer_start_idx: 0
      change_dynamics: false
      channel_num: 5
      clip_grad: 0.5
      concat_option: point_wise
      critic_aux: true
      critic_extra_latent: -1
      critic_goal: false
      dagger: false
      dart: true
      ddpg_coefficients: *id001
      domain_randomization: false
      env_name: PandaYCBEnv
      env_num_objs: 1
      expert_initial_state: true
      explore_cap: 0.5
      explore_ratio: 0.1
      explore_ratio_list: *id002
      feature_input_dim: 512
      fill_data_step: 10
      fix_timestep_test: true
      gamma: 0.95
      goal_reward_flag: false
      head_lr: 0.0003
      hidden_size: 256
      index_file: experiments/object_index/extra_shape.json
      index_split: train
      init_distance_high: 0.45
      init_distance_low: 0.15
      load_buffer: false
      load_obj_num: 40
      load_scene_joint: false
      load_test_scene_new: false
      log: true
      lr: 0.0003
      lr_gamma: 0.5
      max_epoch: 150000
      max_num_pts: 20000
      mix_milestones: *id003
      mix_policy_ratio_list: *id004
      mix_value_ratio_list: *id005
      new_scene: true
      noise_ratio_list: *id006
      noise_type: uniform
      num_remotes: 8
      off_policy: true
      online_buffer_ratio: 0.0
      onpolicy: false
      overwrite_feat_milestone: *id007
      policy_aux: true
      policy_extra_latent: -1
      policy_goal: false
      policy_milestones: *id008
      policy_update_gap: 2
      pt_accumulate_ratio: 0.95
      refill_buffer: true
      reinit_factor: 3
      reinit_lr: 0.0001
      reinit_optim: false
      sa_channel_concat: true
      save_epoch: *id009
      self_supervision: false
      shared_feature: false
      shared_objects_across_worker: false
      target_update_interval: 3000
      tau: 0.0001
      train_feature: true
      train_goal_feature: false
      train_value_feature: true
      uniform_num_pts: 1024
      updates_per_step: 4
      use_action_limit: true
      use_expert_plan: false
      use_image: false
      use_point_state: true
      use_time: true
      value_lr: 0.0003
      value_lr_gamma: 0.5
      value_milestones: *id010
      value_model: false
      visdom: true
  RNG_SEED: 3
  ROBOT_DATA_DIR: data/robots
  ROOT_DIR: /home/weiyang/akash/GA-DDPG/experiments/../
  SCRIPT_FOLDER: experiments/cfgs
  pretrained_time: ''
  script_name: ddpg_finetune.yaml
state:
  DATA_ROOT_DIR: data/scenes
  EPOCHS: 200
  EXPERIMENT_OBJ_INDEX_DIR: experiments/object_index
  IMG_SIZE: *id011
  LOG: true
  MODEL_SPEC_DIR: experiments/model_spec
  OBJECT_DATA_DIR: data/objects
  OFFLINE_BATCH_SIZE: 100
  OFFLINE_RL_MEMORY_SIZE: 100000
  ONPOLICY_MEMORY_SIZE: -1
  OUTPUT_DIR: output
  OUTPUT_MISC_DIR: output_misc
  RL_DATA_ROOT_DIR: data/scenes
  RL_IMG_SIZE: *id012
  RL_MAX_STEP: 20
  RL_MEMORY_SIZE: 100000
  RL_MODEL_SPEC: experiments/model_spec/rl_pointnet_model_spec.yaml
  RL_SAVE_DATA_NAME: data_50k.npz
  RL_SAVE_DATA_ROOT_DIR: data/offline_data
  RL_TEST_SCENE: data/gaddpg_scenes
  RL_TRAIN: *id013
  RNG_SEED: 3
  ROBOT_DATA_DIR: data/robots
  ROOT_DIR: /home/weiyang/akash/GA-DDPG/experiments/../
  SCRIPT_FOLDER: experiments/cfgs
  pretrained_time: ''
  script_name: ddpg_finetune.yaml
